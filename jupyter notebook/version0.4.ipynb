{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cz1544252489/DailyWork/blob/main/jupyter%20notebook/version0.4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b7748856-312f-4b93-aa05-13f72cba6768",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7748856-312f-4b93-aa05-13f72cba6768",
        "outputId": "58b5dbec-ab0d-4c8e-ae43-62262d9d7643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 146275916.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 41814184.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 35591135.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 21096931.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset, random_split\n",
        "\n",
        "def load_dataset2():\n",
        "    # 数据预处理\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    # 加载完整的 MNIST 训练数据集\n",
        "    full_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "    # 随机选择 20,000 个样本\n",
        "    subset_indices = torch.randperm(len(full_dataset))[:20000]\n",
        "    subset_dataset = Subset(full_dataset, subset_indices)\n",
        "\n",
        "    # 将 20,000 个样本分为 5,000 个训练集、5,000 个验证集和 10,000 个测试集\n",
        "    train_set, val_set, test_set = random_split(subset_dataset, [5000, 5000, 10000])\n",
        "\n",
        "    # 打乱训练集中的 2,500 个样本的标签\n",
        "    rand_indices = torch.randperm(len(train_set))[:2500]\n",
        "    for idx in rand_indices:\n",
        "        # 随机生成一个新的标签\n",
        "        new_label = torch.randint(0, 10, (1,)).item()\n",
        "        train_set.dataset.dataset.targets[subset_indices[train_set.indices[idx]]] = new_label\n",
        "\n",
        "    # 创建数据加载器\n",
        "    trainloader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    valloader = DataLoader(val_set, batch_size=64, shuffle=True)\n",
        "    testloader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
        "\n",
        "    return trainloader, valloader, testloader\n",
        "\n",
        "def test(net, testloader):\n",
        "    # 测试网络\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')\n",
        "\n",
        "\n",
        "trainloader, valloader, testloader = load_dataset2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1199e6b0-07f1-42bd-a2a6-3f787c1435ca",
      "metadata": {
        "id": "1199e6b0-07f1-42bd-a2a6-3f787c1435ca"
      },
      "outputs": [],
      "source": [
        "# 定义神经网络\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc = nn.Linear(28*28, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "net_old = SimpleNet()\n",
        "\n",
        "N = 5000\n",
        "la = torch.rand([N,1],requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8f882bed-8e75-4ec4-87ba-176e49c9ed8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f882bed-8e75-4ec4-87ba-176e49c9ed8c",
        "outputId": "78123911-6383-42cf-e068-8853cec2beb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 8.31 %\n",
            "[Epoch 10] lower_loss: 0.654\n",
            "[Epoch 20] lower_loss: 0.539\n",
            "[Epoch 30] lower_loss: 0.504\n",
            "[Epoch 40] lower_loss: 0.574\n",
            "[Epoch 50] lower_loss: 0.492\n",
            "[Epoch 60] lower_loss: 0.518\n",
            "[Epoch 70] lower_loss: 0.505\n",
            "[Epoch 80] lower_loss: 0.534\n",
            "[Epoch 90] lower_loss: 0.479\n",
            "[Epoch 100] lower_loss: 0.475\n",
            "upper_loss: 0.795\n",
            "Accuracy of the network on the 10000 test images: 44.91 %\n"
          ]
        }
      ],
      "source": [
        "# 使用相同的参数以比较优化的好坏\n",
        "net = copy.deepcopy(net_old)\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "def lower_function(output, label, la):\n",
        "    crossentropy = nn.CrossEntropyLoss()\n",
        "    loss = crossentropy(output, label)*la\n",
        "    return loss\n",
        "\n",
        "def upper_function(output, label):\n",
        "    crossentropy = nn.CrossEntropyLoss()\n",
        "    loss = crossentropy(output, label)+0.01*(torch.norm(net.fc.weight)+torch.norm(net.fc.bias))\n",
        "    return loss\n",
        "\n",
        "# SGD的效果明显要比Adam好不少\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
        "\n",
        "# 定义内层循环\n",
        "def inner_loop(trainloader, net, la):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = lower_function(outputs, labels, la[i])\n",
        "        #s = torch.cat((net.fc.weight.data, net.fc.bias.data.view(-1,1)), dim=1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    return running_loss, net\n",
        "\n",
        "# 第一次测试网络\n",
        "test(net, testloader)\n",
        "\n",
        "\n",
        "T = 100\n",
        "# 训练网络\n",
        "for epoch in range(T):\n",
        "    lower_loss, net  = inner_loop(trainloader, net, la)\n",
        "\n",
        "    s = torch.cat((net.fc.weight.data, net.fc.bias.data.view(-1,1)), dim=1).view(-1)\n",
        "    s_grad = torch.cat((net.fc.weight.grad.data, net.fc.bias.grad.data.view(-1,1)), dim=1).view(-1)\n",
        "\n",
        "    if epoch % 10 ==9:\n",
        "        print(f'[Epoch {epoch + 1}] lower_loss: {lower_loss / 200:.3f}')\n",
        "\n",
        "    B = la.grad\n",
        "    A = torch.cat((net.fc.weight.grad.data, net.fc.bias.grad.data.view(-1,1)), dim=1).view(-1)\n",
        "\n",
        "\n",
        "    upper_loss = 0.0\n",
        "    for i, data in enumerate(valloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = upper_function(outputs, labels)\n",
        "\n",
        "        upper_loss += loss\n",
        "\n",
        "\n",
        "print(f'upper_loss: {upper_loss / 200:.3f}')\n",
        "\n",
        "\n",
        "test(net, testloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(net, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tJb7sJbq03L",
        "outputId": "157189b7-67e3-436b-a837-41cbc7e48352"
      },
      "id": "2tJb7sJbq03L",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 44.91 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9cad1066-1f46-473b-af25-cea5ca277ee5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cad1066-1f46-473b-af25-cea5ca277ee5",
        "outputId": "0dc1d83b-f2b7-4769-b089-a8d135fa39f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5969.7881)\n"
          ]
        }
      ],
      "source": [
        "print(torch.norm(la.grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2a3f59d7-678c-40c0-80e8-50123f4b2a9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a3f59d7-678c-40c0-80e8-50123f4b2a9b",
        "outputId": "0ceff813-69fc-4448-c384-7920c9e74830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 784]) torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "print(net.fc.weight.grad.shape,net.fc.bias.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3f7457c2-8808-45ff-a5a3-ebde14c72219",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f7457c2-8808-45ff-a5a3-ebde14c72219",
        "outputId": "219e08f0-40e5-4b10-f0e3-2df7a5148383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7850])\n",
            "torch.Size([7850])\n"
          ]
        }
      ],
      "source": [
        "B = la.grad\n",
        "A = net.fc.weight.grad\n",
        "B = net.fc.bias.grad.view(-1,1)\n",
        "C = torch.cat((A, B),dim=1)\n",
        "s = torch.cat((net.fc.weight.data, net.fc.bias.data.view(-1,1)), dim=1).view(-1)\n",
        "s_grad = torch.cat((net.fc.weight.grad.data, net.fc.bias.grad.data.view(-1,1)), dim=1).view(-1)\n",
        "print(s.shape)\n",
        "print(s_grad.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a06422cd-d925-4055-84e1-dfbf839da975",
      "metadata": {
        "id": "a06422cd-d925-4055-84e1-dfbf839da975"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}